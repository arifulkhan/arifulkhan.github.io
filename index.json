[{"authors":["admin"],"categories":null,"content":"Arif Khan\u0026rsquo;s research interest includes graph algorithm, high performance computing, approximation algorithm along with their applications in bioinformatics, social network and machine learning. His goal is to explore how approximation algorithms can solve big graph problems using leadership class supercomputers.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Arif Khan\u0026rsquo;s research interest includes graph algorithm, high performance computing, approximation algorithm along with their applications in bioinformatics, social network and machine learning. His goal is to explore how approximation algorithms can solve big graph problems using leadership class supercomputers.","tags":null,"title":"","type":"authors"},{"authors":["Arif Khan","Arun Sathanur","Kelsey Maass \u0026 Robert Rallo"],"categories":[],"content":"","date":1594252800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594252800,"objectID":"9476e67b9b6aef2a57801e04b475844f","permalink":"https://arifulkhan.github.io/publication/18/","publishdate":"2020-07-17T14:36:08-07:00","relpermalink":"/publication/18/","section":"publication","summary":"Street-level travel time estimation along with the temporal variations in patterns of travel times is an important component of traffic planning and operation in modern urban settings. In this work, we propose a scalable distributed-computing based methodology to leverage coarse-grained and aggregated travel time data to estimate the street-level travel times of a given metropolitan area. Our approach, termed TranSEC (Transportation State Estimation Capability), leverages easy-to-obtain, aggregated data sets with broad spatial coverage, such as the data published by Uber Movement and can handle road networks of very large size such as whole metropolitan areas. TranSEC is flexible enough to accommodate augmentation with fine-grained but potentially more expensive datasets, such as curated GPS-based data and probe data. Our proposed methodology uses a graph representation of the road network and combines several techniques such as weighted shortest-path routing, a trip sampling and a biased travel time sampling schemes, graph sparsification through betweenness centrality, and an iterative optimization flowthat solves successive constrained least-squares optimization problems. TranSEC further uses graph partitioning tools to enable distributed solution to the problem. We demonstrate our method on the full Los Angeles metropolitan-area where aggregated travel time data is available for trips between traffic analysis zones using a 1280-core supercomputer and visualize the temporal traffic trends at the street-level.","tags":[],"title":"A Distributed Travel Time Estimation Capability for Metropolitan-sized Road Transportation Networks","type":"publication"},{"authors":["Kelsey Maass","Arun Sathanur","Arif Khan \u0026 Robert Rallo"],"categories":[],"content":"","date":1581206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581206400,"objectID":"f62988b1710e91d434ce7525aebbb838","permalink":"https://arifulkhan.github.io/publication/17/","publishdate":"2020-03-17T14:36:08-07:00","relpermalink":"/publication/17/","section":"publication","summary":"Estimating temporal patterns in travel times along road segments in urban settings is of central importance to trac engineers and city planners. In this work, we propose a methodology to leverage coarse-grained and aggregated travel time data to estimate the street-level travel times of a given metropolitan area. Our main fo- cus is to estimate travel times along the arterial road segments where relevant data are often unavailable. The central idea of our approach is to leverage easy- to-obtain, aggregated data sets with broad spatial cov- erage, such as the data published by Uber Movement, as the fabric over which other expensive, fine-grained datasets, such as loop counter and probe data, can be overlaid. Our proposed methodology uses a graph representation of the road network and combines sev- eral techniques such as graph-based routing, trip sam- pling, graph sparsification, and least-squares optimiza- tion to estimate the street-level travel times. Using sampled trips and weighted shortest-path routing, we iteratively solve constrained least-squares problems to obtain the travel time estimates. We demonstrate our method on the Los Angeles metropolitan-area street network, where aggregated travel time data is available for trips between traffic analysis zones. Additionally, we present techniques to scale our approach via a novel graph pseudo-sparsification technique.","tags":[],"title":"Street-level Travel-time Estimation via Aggregated Uber Data","type":"publication"},{"authors":["Arun Sathanur","Vinay Amatya","Arif Khan","Robert Rallo \u0026 Kelsey Maass"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1a4aa3e4c45f2f0bdfc2d32bd6626401","permalink":"https://arifulkhan.github.io/publication/15/","publishdate":"2020-03-17T14:35:55-07:00","relpermalink":"/publication/15/","section":"publication","summary":"In this work, we leverage the Uber movement dataset for the Los Angeles (LA) area where partial TAZ to TAZ (Traffic Analysis Zone) trip time data is available, to predict travel time patterns on the full TAZ to TAZ network. We first create a TAZ-TAZ network based on nearest neighbors and propose a model that allows us to complete the (O −D) (Origin-Destination) travel time matrix, using optimization methods such as non-negative least squares.We apply these algorithms to several communities in the TAZ-TAZ network and present insights in the form of completed (O −D) matrices and associated temporal trends. We qualify the error performance and scalability of our flows. We conclude by pointing out the directions in our ongoing work to improve the quality and scale of travel time estimation.","tags":[],"title":"Graph Analytics and Optimization Methods for Insights from the Uber Movement Data","type":"publication"},{"authors":["Arif Khan","Mahantesh Halappanavar","Tobias Hagge","Karol Kowalski","Alex Pothen \u0026 Sriram Krishnamoorthy"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"9f1469da2f3587f052bb89594723e810","permalink":"https://arifulkhan.github.io/publication/16/","publishdate":"2020-03-17T14:35:58-07:00","relpermalink":"/publication/16/","section":"publication","summary":"We consider an assignment problem arising in Fermionic-swap based mapping of the one-body and two-body interaction terms in simulating time evolution of a sparse second-quantized electronic structure Hamiltonian on a quantum computer. Relative efficiency of different assignment algorithms depends on the relative costs of performing a swap and computing a Hamiltonian interaction term. Under the assumption that the interaction term cost dominates the computation, we develop an iterative algorithm that uses minimum cost linear assignment (MINLA) and matching for one-body interactions, and hypergraph optimal linear arrangement (HOLA) and partial distance-2 coloring for two-body interactions, to exploit arbitrary sparsity in the Hamiltonian for efficient computation. Using a set of 122 problems from computational chemistry, we demonstrate performance improvements up to 100% relative to the state-ofthe- art approach for one-body terms and up to 86% utilization for two-body terms relative to a theoretical peak utilization. To the best of our knowledge, this is the first study to exploit arbitrary sparsity in orbital interactions for efficient computation on one-dimensional qubit connectivity layouts. The proposed algorithms lay a foundation for extension to map general k-body interactions that arise in many domains onto generalized qubit connectivity layouts available in current and future quantum systems.","tags":[],"title":"Mapping Arbitrarily Sparse Two-body Interactions on One-dimensional Quantum Circuits","type":"publication"},{"authors":["Arif Khan","Krzysztof Choromanski","Alex Pothen","S M Ferdous","Mahantesh Halappanavar \u0026 Antonino Tumeo"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"f3a861b95ca2be9dad2207cf865ce7d6","permalink":"https://arifulkhan.github.io/publication/14/","publishdate":"2020-03-16T16:55:36-07:00","relpermalink":"/publication/14/","section":"publication","summary":"We explore the problem of sharing data that pertains to individuals with anonymity guarantees, where each user requires a desired level of privacy. We propose the first sharedmemory as well as distributed memory parallel algorithms for the adaptive anonymity problem that achieves this goal, and produces high quality anonymized datasets. The new algorithm is based on an optimization procedure that iteratively computes weights on the edges of a dissimilarity matrix, and at each iteration computes a minimum weighted b-Edge Cover in the graph. We describe how a 2-approximation algorithm for computing the b-Edge Cover can be used to solve the adaptive anonymity problem in parallel. We are able to solve adaptive anonymity problems with hundreds of thousands of instances and hundreds of features on a supercomputer in under five minutes. Our algorithm scales up to 8K cores on a distributed memory supercomputer, while also providing good speedups on shared memory multiprocessors. On smaller problems where an a Belief Propagation algorithm is feasible, our algorithm is two orders of magnitude faster.","tags":[],"title":"Adaptive Anonymization of Data using b-Edge Cover","type":"publication"},{"authors":["S M Ferdous","Alex Pothen \u0026 Arif Khan"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"de4ca9ffc06fb2e510d9e62536902337","permalink":"https://arifulkhan.github.io/publication/13/","publishdate":"2020-03-16T16:55:33-07:00","relpermalink":"/publication/13/","section":"publication","summary":"We describe two new 3=2-approximation algorithms and a new 2-approximation algorithm for the minimum weight edge cover problem in graphs. We show that one of the 3=2-approximation algorithms, the Dual Cover algorithm, computes the lowest weight edge cover relative to previously known algorithms as well as the new algorithms reported here. The Dual Cover algorithm can also be implemented to be faster than the other 3=2-approximation algorithms on serial computers. Many of these algorithms can be extended to solve the b-Edge Cover problem as well. We show the relation of these algorithms to the K-Nearest Neighbor graph construction in semi-supervised learning and other applications.","tags":[],"title":"New Approximation Algorithms for Minimum Weighted Edge Cover","type":"publication"},{"authors":["Sayan Ghosh","Mahantesh Halappanavar","Antonino Tumeo","Ananth Kalyanaraman","Hao Lu","Daniel Chavarria-Miranda","Arif Khan \u0026 Assefaw Gebremedhin"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"0ff81c23c6cea7044cd7e61fdc798522","permalink":"https://arifulkhan.github.io/publication/11/","publishdate":"2020-03-16T16:55:29-07:00","relpermalink":"/publication/11/","section":"publication","summary":"In most real-world networks, the nodes/vertices tend to be organized into tightly-knit modules known as communities or clusters, such that nodes within a community are more likely to be “related” to one another than they are to the rest of the network. The goodness of partitioning into communities is typically measured using a well known measure called modularity. However, modularity optimization is an NP-complete problem. In 2008, Blondel, et al. introduced a multi-phase, iterative heuristic for modularity optimization, called the Louvain method. Owing to its speed and ability to yield high quality communities, the Louvain method continues to be one of the most widely used tools for serial community detection. In this paper, we present the design of a distributed memory implementation of the Louvain algorithm for parallel community detection. Our approach begins with an arbitrarily partitioned distributed graph input, and employs several heuristics to speedup the computation of the different steps of the Louvain algorithm. We evaluate our implementation and its different variants using real-world networks from various application domains (including internet, biology, social networks). Our MPI+OpenMP implementation yields about 7x speedup (on 4K processes) for soc-friendster network (1.8B edges) over a state-of-the-art shared memory multicore implementation (on 64 threads), without compromising output quality. Furthermore, our distributed implementation was able to process a larger graph (uk-2007; 3.3B edges) in 32 seconds on 1K cores (64 nodes) of NERSC Cori, when the state-of-the-art shared memory implementation failed to run due to insufficient memory on a single Cori node containing 128 GB of memory.","tags":[],"title":"Distributed Louvain Algorithm for Graph Community Detection.","type":"publication"},{"authors":["Arif Khan","Alex Pothen \u0026 S M Ferdous"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ca95160359fdb57bcb60894a7273ae05","permalink":"https://arifulkhan.github.io/publication/12/","publishdate":"2020-03-16T16:55:31-07:00","relpermalink":"/publication/12/","section":"publication","summary":"Abstract—We describe a paradigm for designing parallel algorithms via approximation, and illustrate it on the b-EDGE COVER problem. A b-EDGE COVER of minimum weight in a graph is a subset C of its edges such that at least a specified number b(v) of edges in C is incident on each vertex v, and the sum of the edge weights in C is minimum. The GREEDY algorithm and a variant, the LSE algorithm, provide 3=2-approximation guarantees in the worst-case for this problem, but these algorithms have limited parallelism. Hence we design two new 2-approximation algorithms with greater concurrency. The MCE algorithm reduces the computation of a b-EDGE COVER to that of finding a b0-MATCHING, by exploiting the relationship between these subgraphs in an approximation context. The S-LSE is derived from the LSE algorithm using static edge weights rather than dynamically computing effective edge weights. This relaxation gives S-LSE a worse approximation guarantee but makes it more amenable to parallelization. We prove that both the MCE and S-LSE algorithms compute the same b-EDGE COVER with at most twice the weight of the minimum weight edge cover. In practice, the 2-approximation and 3=2-approximation algorithms compute edge covers of weight within 10% the optimal. We implement three of the approximation algorithms, MCE, LSE, and S-LSE, on shared memory multi-core machines, including an Intel Xeon and an IBM Power8 machine with 8 TB memory. The MCE algorithm is the fastest of these by an order of magnitude or more. It computes an edge cover in a graph with billions of edges in 20 seconds using two hundred threads on the IBM Power8. We also show that the parallel depth and work can be bounded for the SUITOR and b-SUITOR algorithms when edge weights are random.","tags":[],"title":"Parallel Algorithms through Approximation: b-Edge Cover.","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://arifulkhan.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Arif Khan \u0026 Alex Pothen"],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"7b631e4361a243ff282aec387d00bc8f","permalink":"https://arifulkhan.github.io/publication/9/","publishdate":"2020-03-16T16:55:23-07:00","relpermalink":"/publication/9/","section":"publication","summary":"We describe a 3/2-approximation algorithm, LSE, for computing a b-Edge Cover of minimum weight in a graph with weights on the edges. The b-Edge Cover problem is a generalization of the better-known Edge Cover problem in graphs, where the objective is to choose a subset C of edges in the graph such that at least a specified number b(v) of edges in C are incident on each vertex v. In the weighted b-Edge Cover problem, we minimize the sum of the weights of the edges in C. We prove that the LSE algorithm computes the same b-Edge Cover as the one obtained by the Greedy algorithm for the problem. However, the Greedy algorithm requires edges to be sorted by their effective weights, and these weights need to be updated after each iteration. These requirements make the Greedy algorithm sequential and impractical for massive graphs. The LSE algorithm avoids the sorting step, and is amenable for parallelization. We implement the algorithm on a serial machine and compare its performance against a collection of approximation algorithms for the b-Edge Cover problem. Our results show that the LSE algorithm is 3× to 5× faster than the Greedy algorithm on a serial processor. The approximate edge covers obtained by the LSE algorithm have weights greater by at most 17% of the optimal weight for problems where we could compute the latter. We also investigate the relationship between the b-Edge Cover and the b-Matching problems, show that the latter has a faster implementation since edge weights are static in this algorithm, and obtain a heuristic solution for the former from the latter.","tags":[],"title":"A new 3/2-approximation algorithm for b-Edge Cover Problem","type":"publication"},{"authors":["Arif Khan","Alex Pothen","Mostofa Patwary","Nadathur Satish","Narayanan Sunderam","Mahantesh Halappanavar \u0026 Pradeep Dubey"],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"7af5f6c6ae65e6649c08f65c71d2e54f","permalink":"https://arifulkhan.github.io/publication/10/","publishdate":"2020-03-16T16:55:27-07:00","relpermalink":"/publication/10/","section":"publication","summary":"b-MATCHING is a subset of edges M such that at most b(v) edges in M are incident on each vertex v, where b(v) is specified. We present a distributed-memory parallel algorithm, b-SUITOR, that computes a b-MATCHING with more than half the maximum weight in a graph with weights on the edges. The approximation algorithm is designed to have high concurrency and low time complexity. We organize the implementation of the algorithm in terms of asynchronous supersteps that combine computation and communication, and balance the computational work and frequency of communication to obtain high performance. Since the performance of the b-SUITOR algorithm is strongly influenced by communication, we present several strategies to reduce the communication volume. We implement the algorithm using a hybrid strategy where inter-node communication uses MPI and intra-node computation is done with OpenMP threads. We demonstrate strong and weak scaling of b-SUITOR up to 16K processors on two supercomputers at NERSC. We compute a b-MATCHING in a graph with 2 billion edges in under 4 seconds using 16K processors.","tags":[],"title":"Designing Scalable b-MATCHING Algorithms on Distributed Memory Multiprocessors by Approximation","type":"publication"},{"authors":["Mahantesh Halappanavar","Alex Pothen","Ariful Azad","Fredrik Manne","Johannes Langguth \u0026 Arif Khan"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"600c6e9a5e5581965fd099b24be85ad7","permalink":"https://arifulkhan.github.io/publication/7/","publishdate":"2020-03-16T16:55:18-07:00","relpermalink":"/publication/7/","section":"publication","summary":"Executing irregular, data-intensive workloads on multithreaded architectures can result in performance losses and scalability problems. Codesigning algorithms and architectures can realize high performance on irregular applications. A codesign study reveals four key lessons learned from implementing matching algorithms on various platforms","tags":[],"title":"Codesign Lessons Learned from Implementing Graph Matching on Multithreaded Architectures.","type":"publication"},{"authors":["Arif Khan","Alex Pothen","Mostofa Patwary","Nadathur Satish","Narayanan Sunderam","Fredrik Manne","Mahantesh Halappanavar \u0026 Pradeep Dubey"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"a681461fae55d5dacc4c270d16511ffe","permalink":"https://arifulkhan.github.io/publication/8/","publishdate":"2020-03-16T16:55:20-07:00","relpermalink":"/publication/8/","section":"publication","summary":"weight in a graph with weights on the edges. b-Matching is a generalization of the well-known Matching problem in graphs, where the objective is to choose a subset of M edges in the graph such that at most a specified number b(v) of edges in M are incident on each vertex v. Subject to this restriction we maximize the sum of the weights of the edges in M. We prove that the b-Suitor algorithm computes the same b-Matching as the one obtained by the greedy algorithm for the problem. We implement the algorithm on serial and shared-memory parallel processors, and compare its performance against a collection of approximation algorithms that have been proposed for the Matching problem. Our results show that the b-Suitor algorithm outpeforms the Greedy and Locally Dominant edge algorithms by one to two orders of magnitude on a serial processor. The b-Suitor algorithm has a high degree of concurrency, and it scales well up to 240 threads on a shared memory multiprocessor. The b-Suitor algorithm outperforms the Locally Dominant edge algorithm by a factor of fourteen on 16 cores of an Intel Xeon multiprocessor.","tags":[],"title":"Efficient approximation algorithms for weighted b-Matching. SIAM Journal on Scientific Computing","type":"publication"},{"authors":["Ariful Azad","Arif Khan","Bartek Rajwa","Saumyadipta Pyne \u0026 Alex Pothen"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"b3097097d85848fb32f500f754dba046","permalink":"https://arifulkhan.github.io/publication/6/","publishdate":"2020-03-16T16:55:16-07:00","relpermalink":"/publication/6/","section":"publication","summary":"We describe an algorithm to dynamically classify flow cy- tometry data samples into several classes based on their im- munophenotypes. Flow cytometry data consists of fluores- cence measurements of several proteins that characterize dif- ferent cell types in blood or cultured cell lines. Each sample is initially clustered to identify the cell populations present in it. Using a combinatorial dissimilarity measure between cell populations in samples, we compute meta-clusters that correspond to the same cell population across samples. The collection of meta-clusters in a class of samples then de- scribes a template for that class. We organize the samples into a template tree, and use it to classify new samples into existing classes or create a new class if needed. We dynam- ically update the templates and their statistical parameters as new samples are classified, so that the new information is reflected in the classes. We use our dynamic classifica- tion algorithm to classify T cells that on stimulation with an antibody show increased abundance of the proteins SLP- 76 and ZAP-70. These proteins are involved in a platform that assembles signaling proteins in the immune response. We also use the algorithm to show that variation in an im- mune subsystem between individuals is a larger effect than variation in multiple samples from one individual.","tags":[],"title":"Classifying Immunophenotypes with Templates from Flow Cytometry","type":"publication"},{"authors":["Arif Khan","David Gleich","Mahantesh Halappanavar \u0026 Alex Pothen"],"categories":[],"content":"","date":1347148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1347148800,"objectID":"e86d11e4e78f0023a051dcbc76a02c05","permalink":"https://arifulkhan.github.io/publication/5/","publishdate":"2020-03-16T16:55:14-07:00","relpermalink":"/publication/5/","section":"publication","summary":"Network alignment is an optimization problem to find the best one-to-one map between the vertices of a pair of graphs that overlaps as many edges as possible. It is a relaxation of the graph isomorphism problem and is closely related to the subgraph isomorphism problem. The best current approaches are entirely heuristic and iterative in nature. They generate real-valued heuristic weights that must be rounded to find integer solutions. This rounding requires solving a bipartite maximum weight matching problem at each iteration in order to avoid missing high quality solutions. We investigate substituting a parallel, half-approximation for maximum weight matching instead of an exact computation. Our experiments show that the resulting difference in solution quality is negligible. We demonstrate almost a 20-fold speedup using 40 threads on an 8 processor Intel Xeon E7-8870 system and now solve real-world problems in 36 seconds instead of 10 minutes.","tags":[],"title":"A Multithreaded Algorithm for Network Alignment via Approximate Matching.","type":"publication"},{"authors":["Ariful Azad","Mahantesh Halappanavar","Sivasankaran Rajamanickam","Erik G. Boman","Arif Khan \u0026 Alex Pothen"],"categories":[],"content":"","date":1341619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1341619200,"objectID":"8b4dbaef88dd2e19cc11689be16ba2d5","permalink":"https://arifulkhan.github.io/publication/4/","publishdate":"2020-03-16T16:55:12-07:00","relpermalink":"/publication/4/","section":"publication","summary":"We design, implement, and evaluate algorithms for computing a matching of maximum cardinality in a bipartite graph on multi-core and massively multithreaded computers. As computers with larger number of slower cores dominate the commodity processor market, the design of multithreaded algorithms to solve large matching problems becomes a necessity. Recent work on serial algorithms based on searching for augmenting paths for this problem have shown that their performance is sensitive to the order in which the vertices are processed for matching. In a multithreaded environment, imposing a serial order in which vertices are considered for matching would lead to loss of concurrency and performance. But this raises the question: Would parallel matching algorithms on multithreaded machines improve performance over a serial algorithm? We answer this question in the affirmative. We report efficient multithreaded implementations of two key algorithms (Hopcroft- Karp based on breadth-first-search, and Pothen-Fan based on depth-first-search) and their variants, combined with the Karp- Sipser initialization algorithm. We report extensive results and insights using three shared-memory platforms (a 48-core AMD Opteron, a 32-core Intel Nehalem, and a 128-processor Cray XMT) on a representative set of real-world and synthetic graphs. To the best of our knowledge, this is the first extensive study of augmentation-based parallel algorithms for bipartite cardinality matching.","tags":[],"title":"Multithreaded Algorithms for Maximum Matching in Bipartite Graphs.","type":"publication"},{"authors":["Arif Khan \u0026 Markus Schneider"],"categories":[],"content":"","date":1280620800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1280620800,"objectID":"0dd5b0ac39124b270654ab011a52f7d9","permalink":"https://arifulkhan.github.io/publication/3/","publishdate":"2020-03-16T16:55:10-07:00","relpermalink":"/publication/3/","section":"publication","summary":"Reasoning about space has been a considerable field of study both in Artificial Intelligence and in spatial information theory. Many applications benefit from the inference of new knowledge about the spatial relationships between spatial objects on the basis of already available and explicit spatial relationship knowledge that we call spatial (relation- ship) facts. Hence, the task is to derive new spatial facts from known spatial facts. A considerable amount of work has focused on reasoning about topological relationships (as a special and important subset of spatial relationships) between simple spatial objects like simple regions. There is a common consensus in the GIS and spatial database communities that simple regions are insufficient to model spatial reality and that complex region objects are needed that allow multiple components and holes. Models for topological relationships between complex regions have already been developed. Hence, as the next logical step, the goal of this paper is to develop a reasoning model for them. Further, no reasoning model considers changes of the spatial fact basis stored in a database between consecutive queries. We show that conventional modeling suffers from performance degradation when the database is frequently changing. Our model does not assume any geometric representation model or data structure for the regions. The model is also backward compatible, i.e., it is also applicable to simple regions.","tags":[],"title":"Topological Reasoning between Complex Regions in Databases with Frequent Updates","type":"publication"},{"authors":["Tao Chen","Arif Khan","Markus Schneider \u0026 Ganesh Viswanathan"],"categories":[],"content":"","date":1277942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277942400,"objectID":"8eb2070c9756a7c670072b1a7052cdc3","permalink":"https://arifulkhan.github.io/publication/2/","publishdate":"2020-03-16T16:55:08-07:00","relpermalink":"/publication/2/","section":"publication","summary":"technologies have necessitated the handling of complex application objects that are highly structured, large, and of variable length. Currently, such objects are handled using filesystem formats like HDF and NetCDF as well as the XML and BLOB data types in databases. However, some of these approaches are very application specific and do not provide proper levels of data abstraction for the users. Others do not support random updates or cannot manage large volumes of structured data and provide their associated operations. In this paper, we propose a novel two-step solution to manage and query application objects within databases. First, we present a generalized conceptual framework to capture and validate the structure of application objects by means of a type structure specification. Second, we introduce a novel data type called Intelligent Binary Large Object (iBLOB) that leverages the traditional BLOB type in databases, preserves the structure of application objects, and provides smart query and update capabilities. The iBLOB framework generates a type structure specific application programming interface (API) that allows applications to easily access the components of complex application objects. This greatly simplifies the ease with which new type systems can be implemented inside traditional DBMS.","tags":[],"title":"iBLOB: Complex Object Management in Databases Through Intelligent BLOB","type":"publication"},{"authors":["Markus Schneider","Shen-Shyang Ho","Tao Chen","Arif Khan"],"categories":[],"content":"","date":1275782400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1275782400,"objectID":"e35ee5d6a2d0b25ff2db4054cbb402aa","permalink":"https://arifulkhan.github.io/publication/1/","publishdate":"2010-06-06T00:00:00Z","relpermalink":"/publication/1/","section":"publication","summary":"Abstract—Existing state-of-the-art and web-based weather event information portals, data archives, and forecast services provide excellent subsetting and visualizations of weather events and satellite sensor measurements. However, users only obtain limited, simple, and hard-coded query, retrieval, and analysis capabilities from these sources. One non-existent but desirable capability is the accurate and efficient ad-hoc querying of the trajectories of dynamic atmospheric events (e.g., tropical cyclones, hurricanes) as well as the efficient retrieval of Earth science satellite sensor data for these events based on ad-hoc, user defined criteria and the event trajectories. In this paper, we describe our current work and progress in the development of a sophisticated framework based on the moving objects database technology for ad-hoc querying and retrieval of atmospheric events and their associated satellite measurements. Such a capability is extremely important to scientists who process sensor data of atmospheric events for statistical analysis and scientific investigation.","tags":[],"title":"Moving Object Database Technology for Ad-Hoc Querying and Satellite Data Retrieval of Dynamic Atmospheric Events","type":"publication"}]